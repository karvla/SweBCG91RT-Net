{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  U-Net trained on public datasets\n",
    "This notebook is for training a model on public data. The goal is to train a model that will be used to find cell instances in the data from the SweBCH91RT study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu = tf.config.experimental.list_physical_devices(\"GPU\")[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, multiply\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from weighted_loss_unet import make_weighted_loss_unet, my_loss\n",
    "from augmented_sequence import AugmentedSequence\n",
    "\n",
    "import config\n",
    "import importlib\n",
    "\n",
    "importlib.reload(config)\n",
    "c = config.Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing annotations in /tank/data/arvid/SweBCG91RT-Net/data/quip/annotations\n"
     ]
    }
   ],
   "source": [
    "import augmented_dataset\n",
    "\n",
    "importlib.reload(augmented_dataset)\n",
    "from augmented_dataset import AugmentedDataset\n",
    "from dataset import Monuseg, Bns, Quip\n",
    "import random\n",
    "import time\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # iaa.CropToFixedSize(width=round(c.WIDTH*4.0), height=round(c.HEIGHT*4.0)),\n",
    "        # iaa.flip.Flipud(p=0.25),\n",
    "        # iaa.flip.Fliplr(p=0.25),\n",
    "        # iaa.Affine(rotate=(0,360),\n",
    "        #           scale={\"x\":(0.8, 1.2), \"y\":(0.8, 1.2)},\n",
    "        #           shear=(-8, 8)),\n",
    "        iaa.CropToFixedSize(width=c.WIDTH, height=c.HEIGHT),\n",
    "        # iaa.Resize({\"height\" : c.HEIGHT,  \"width\" : c.WIDTH}),\n",
    "        # iaa.Sometimes(0.2, iaa.GaussianBlur(sigma=(0.0, 1.0))),\n",
    "        # iaa.AddToHue((-25, 25)),\n",
    "        # iaa.Sometimes(0.2, iaa.EdgeDetect((0,0.5)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_sequential = iaa.Sequential(\n",
    "    [\n",
    "        iaa.CropToFixedSize(width=c.WIDTH, height=c.HEIGHT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_train = AugmentedDataset(Quip(), seq, 1, scale=0.5).prefetch(\n",
    "    tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Sanity check\n",
    "(img_b, wmap_b), mask_b = ds_train.as_numpy_iterator().__next__()\n",
    "print(img_b.shape, wmap_b.shape, mask_b.shape)\n",
    "print(img_b.dtype, wmap_b.dtype, mask_b.dtype)\n",
    "\n",
    "img = img_b[0]\n",
    "wmap = wmap_b[1, ..., 2]\n",
    "mask = mask_b[1, ..., 0]\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(wmap)\n",
    "plt.title(\"Weight map\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(mask)\n",
    "plt.title(\"Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ## Train U-Net\n",
    "# The U-Net, along with the weight map loss function, was implemented by [jaidevd](https://jaidevd.github.io/posts/weighted-loss-functions-for-instance-segmentation/).\n",
    "def iou(y_true, y_pred):\n",
    "    y_true = y_true[0]\n",
    "    intersection = K.sum(K.abs(y_true[..., 1] * y_pred[..., 1]), axis=-1)\n",
    "    union = K.sum(K.abs(y_true[..., 1]) + K.abs(y_pred[..., 1]), axis=-1)\n",
    "    jac = (intersection) / (union)\n",
    "    return 1 - jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "name = f\"unet_quip_{c.EPOCHS}\"\n",
    "model_dir = \"../models/unet\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "if f\"{name}.h5\" in os.listdir(model_dir):\n",
    "    print(\"Loading existing model...\", end=\"\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{model_dir}/{name}.h5\", custom_objects={\"my_loss\": my_loss, \"iou\": iou}\n",
    "    )\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    wandb.init(project=\"histosnet\")\n",
    "    model = make_weighted_loss_unet(is_training=True)\n",
    "    model.compile(optimizer=\"adam\", loss=my_loss)\n",
    "    model.fit(ds_train, epochs=c.EPOCHS, callbacks=[WandbCallback()])\n",
    "\n",
    "    model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    # Our inference model won't take a weight map as an input.\n",
    "    model_inference = make_weighted_loss_unet(is_training=False)\n",
    "    model_inference.set_weights(model.get_weights())\n",
    "    model_inference.save(f\"{model_dir}/{name}.h5\")\n",
    "    model = model_inference\n",
    "\n",
    "\n",
    "# # Post-processing\n",
    "# We use some of the techniques found in the [NucleAIzer Paper](https://www.sciencedirect.com/science/article/pii/S2405471220301174).\n",
    "# 1. Descide on optimal threshold.\n",
    "# 2. Remove small holes.\n",
    "# 3. Remove small objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import skimage.morphology as morphology\n",
    "from scipy.optimize import minimize\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "def make_sequence(patient_ids):\n",
    "    \"\"\" Making a regular sequence without any augmentations. \"\"\"\n",
    "    crop_seq = iaa.Sequential([iaa.CropToFixedSize(width=IMG_WIDTH, height=IMG_HEIGHT)])\n",
    "    return AugmentedSequence(patient_ids, BATCH_SIZE, crop_seq, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred).sum()\n",
    "    union = np.logical_or(y_true, y_pred).sum()\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def mean_iou(y_true: list, y_pred: list):\n",
    "    return np.mean([iou(yt, yp) for yt, yp in zip(y_true, y_pred)])\n",
    "\n",
    "\n",
    "img_batches, y_true_batches = zip(\n",
    "    *[\n",
    "        (img_b, mask_b)\n",
    "        for (img_b, _), mask_b in islice(ds_train.as_numpy_iterator(), 18)\n",
    "    ]\n",
    ")\n",
    "y_pred_batches = [model.predict(img_b) for img_b in img_batches]\n",
    "\n",
    "y_true = [y[..., 1] + y[..., 2] for batch in y_true_batches for y in batch]\n",
    "y_pred = [y[..., 1] for batch in y_pred_batches for y in batch]\n",
    "\n",
    "\n",
    "def loss(p):\n",
    "    return -mean_iou(y_true, [post_processing(y, p) for y in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Optimize post-processing parameters\n",
    "def post_processing(prediction, p):\n",
    "    prediction = prediction > p[0]\n",
    "    prediction = morphology.remove_small_holes(prediction, area_threshold=p[1])\n",
    "    # prediction = morphology.remove_small_objects(prediction, min_size=p[2])\n",
    "    prediction = morphology.dilation(prediction, morphology.square(int(p[2])))\n",
    "    return prediction\n",
    "\n",
    "\n",
    "p = [0.5, 5, 5]\n",
    "p_optimal = minimize(loss, p, method=\"Nelder-Mead\", options={\"disp\": True})\n",
    "p = p_optimal[\"x\"]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = 1\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(y_pred[n])\n",
    "plt.subplot(132)\n",
    "plt.imshow(post_processing(y_pred[n], p))\n",
    "plt.subplot(133)\n",
    "plt.imshow(y_true[n])\n",
    "\n",
    "\n",
    "# # Predict of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_result(model, aug_sequence, batch_limit=1):\n",
    "    for n, ((img_b, _), mask_b) in enumerate(aug_sequence):\n",
    "        if n > batch_limit:\n",
    "            break\n",
    "        prediction = model.predict(img_b)\n",
    "        for img, mask, pred in zip(img_b, mask_b, prediction):\n",
    "            y_true = mask[:, :, 1] + mask[..., 2]\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.subplot(141)\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Image\")\n",
    "\n",
    "            plt.subplot(142)\n",
    "            plt.imshow(y_true)\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            plt.subplot(143)\n",
    "            plt.imshow(pred[:, :, 1])\n",
    "            plt.title(\"Predicted\")\n",
    "\n",
    "            plt.subplot(144)\n",
    "            pred = post_processing(pred[..., 1], p)\n",
    "            intersection = np.logical_and(y_true, pred).sum()\n",
    "            union = np.logical_or(y_true, pred).sum()\n",
    "            iou = round(intersection / union, 2)\n",
    "            plt.imshow(pred)\n",
    "            plt.title(f\"IoU: {iou}\")\n",
    "\n",
    "\n",
    "display_result(model, ds_train)\n",
    "\n",
    "\n",
    "# # Predict on TNBC set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import dataset\n",
    "from dataset import TNBC1\n",
    "from tqdm import tqdm\n",
    "\n",
    "tnbc = TNBC1()\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield np.array(lst[i : i + n])\n",
    "\n",
    "\n",
    "tnbc_sequential = iaa.Sequential(\n",
    "    [\n",
    "        iaa.CropToFixedSize(\n",
    "            width=int(c.WIDTH / 2), height=int(c.HEIGHT / 2), position=\"center\"\n",
    "        ),\n",
    "        iaa.Resize({\"height\": c.HEIGHT, \"width\": c.WIDTH}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "images = [tnbc.load_image(pid) for pid in tnbc.ids[40:45]]\n",
    "for img_b in chunks(tnbc_sequential(images=images), c.BATCH_SIZE):\n",
    "    prediction = model.predict(img_b)\n",
    "    for img, pred in zip(img_b, prediction):\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Image\")\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(pred[:, :, 1])\n",
    "        plt.title(\"Predicted\")\n",
    "\n",
    "        plt.subplot(133)\n",
    "        pred = post_processing(pred[..., 1], p)\n",
    "        plt.imshow(pred)\n",
    "        plt.title(\"Processed\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "SweBCG91RT-Net",
   "language": "python",
   "name": "swebcg91rt-net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
