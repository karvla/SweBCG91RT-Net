{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  U-Net trained on the MoNuSeg data set\n",
    "This notebook is for training a model on the data from the MonSeg challenge. The goal is to train a model that will be used to find cell instances in the data from the SweBCH91RT study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from itertools import cycle\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.draw import polygon\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from keras.utils import Sequence\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, multiply\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import utils\n",
    "from weighted_loss_unet import make_weighted_loss_unet, my_loss\n",
    "\n",
    "from augmented_sequence import AugmentedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training, validation and test groups\n",
    "Should use all MoNuSeg data, not only the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monuseg_patinfo = pd.read_csv(Path(os.getcwd()).parent / 'data/monuseg/patient_information.csv')\n",
    "\n",
    "monuseg_train_ids = monuseg_patinfo[monuseg_patinfo['training'] == 'yes']['patient_id']\n",
    "monuseg_test_ids = monuseg_patinfo[monuseg_patinfo['training'] == 'no']['patient_id']\n",
    "monuseg_train_ids, monuseg_val_ids = utils.val_split(monuseg_train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.CropToFixedSize(width=round(IMG_WIDTH*1.5), height=round(IMG_HEIGHT*1.5)),\n",
    "    iaa.flip.Flipud(p=0.5),\n",
    "    iaa.flip.Fliplr(p=0.5),\n",
    "    #iaa.Affine(rotate=(-45,45)),\n",
    "    iaa.CropToFixedSize(width=IMG_WIDTH, height=IMG_HEIGHT, position=\"center\"),\n",
    "    iaa.Sometimes(0.2, iaa.SigmoidContrast(gain=(3, 10), cutoff=(0.4, 0.6))),\n",
    "    iaa.Sometimes(0.2, iaa.GaussianBlur(sigma=(0.0, 3.0)))\n",
    "    #iaa.Sometimes(0.2, iaa.EdgeDetect((0,0.5)))\n",
    "])\n",
    "\n",
    "val_sequential = iaa.Sequential([\n",
    "    iaa.CropToFixedSize(width=round(IMG_WIDTH*1.5), height=round(IMG_HEIGHT*1.5)),\n",
    "    iaa.flip.Flipud(p=0.5),\n",
    "    iaa.flip.Fliplr(p=0.5),\n",
    "    iaa.Affine(rotate=(-45,45)),\n",
    "    iaa.CropToFixedSize(width=IMG_WIDTH, height=IMG_HEIGHT, position=\"center\"),\n",
    "])\n",
    "\n",
    "train_seq = AugmentedSequence(monuseg_train_ids, BATCH_SIZE, seq, IMG_WIDTH, IMG_HEIGHT)\n",
    "val_seq = AugmentedSequence(monuseg_val_ids, BATCH_SIZE, val_sequential, IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_b, wmap_b), mask_b = train_seq[0]\n",
    "img = img_b[0]\n",
    "wmap = wmap_b[2,:,:,1]\n",
    "mask = mask_b[0,:,:,1]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(wmap)\n",
    "plt.title(\"Weight map\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(mask)\n",
    "plt.title(\"Mask\")\n",
    "# ## Train U-Net\n",
    "# The U-Net, along with the weight map loss function, was implemented by [jaidevd](https://jaidevd.github.io/posts/weighted-loss-functions-for-instance-segmentation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection) / (union)\n",
    "    return (1-jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "name = 'unet_model'\n",
    "if f\"{name}.h5\" in os.listdir('./models/'):\n",
    "    print(\"Loading existing model...\", end='')\n",
    "    model = keras.models.load_model(f'./models/{name}.h5',\n",
    "                        custom_objects={'my_loss' : my_loss, 'iou': iou})\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    wandb.init(project=\"swebcg91rt-net\")\n",
    "    model = make_weighted_loss_unet((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), 2, is_training = True)\n",
    "    model.compile(optimizer='adam', loss=my_loss, metrics=[iou])\n",
    "    model.fit(train_seq, validation_data=val_seq, epochs=300, callbacks=[WandbCallback()]) \n",
    "\n",
    "    # Save model to wandb\n",
    "    model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    model.save(f'./models(unet_model_{time()}.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Post-processing\n",
    "We use some of the techniques found in the [NucleAIzer Paper](https://www.sciencedirect.com/science/article/pii/S2405471220301174).\n",
    "1. Remove small objects entierly within larger objects.\n",
    "2. Objects smaller than p1 pixels are removed.\n",
    "3. Descide on optimal threshold, p2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inference model won't take a weight map as an input.\n",
    "model_inference = make_weighted_loss_unet((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS), 2, False)\n",
    "model_inference.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.morphology as morphology\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def post_processing(prediction, p):\n",
    "    prediction = (prediction > p[0])\n",
    "    prediction = morphology.area_closing(prediction, area_threshold=p[1])\n",
    "    prediction = morphology.remove_small_holes(prediction, area_threshold=p[2])\n",
    "    prediction = morphology.remove_small_objects(prediction, min_size=p[3])\n",
    "    return prediction\n",
    "\n",
    "def make_sequence(patient_ids):\n",
    "    \"\"\" Making a regular sequence without any augmentations. \"\"\"\n",
    "    crop_seq = iaa.Sequential([iaa.CropToFixedSize(width=IMG_WIDTH, height=IMG_HEIGHT)])\n",
    "    return AugmentedSequence(patient_ids, BATCH_SIZE, crop_seq, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred).sum()\n",
    "    union = np.logical_or(y_true, y_pred).sum()\n",
    "    return intersection / union\n",
    "\n",
    "def mean_iou(y_true: list, y_pred : list):\n",
    "    return np.mean([iou(yt, yp) for yt, yp in zip(y_true, y_pred)])\n",
    "\n",
    "img_batches, y_true_batches = zip(*[(img_b, mask_b) for (img_b, _), mask_b in val_seq])\n",
    "y_pred_batches = [model_inference.predict(img_b) for img_b in img_batches]\n",
    "\n",
    "y_true = [y[...,1] for batch in y_true_batches for y in batch ]\n",
    "y_pred = [y[...,1] for batch in y_pred_batches for y in batch ]\n",
    "\n",
    "def loss(p):\n",
    "    return - mean_iou(y_true, [post_processing(y, p) for y in y_pred])\n",
    "\n",
    "p_optimal = minimize(loss, (0.7, 64, 64, 64), method='Nelder-Mead', options={'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p_optimal[\"x\"]\n",
    "print(p)\n",
    "n=1\n",
    "plt.figure()\n",
    "plt.imshow(y_pred[n])\n",
    "plt.figure()\n",
    "plt.imshow(post_processing(y_pred[n], p))\n",
    "plt.figure()\n",
    "plt.imshow(y_true[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(model, aug_sequence, threshold=0.5, batch_limit=1):\n",
    "    for n, ((img_b, _), mask_b) in enumerate(aug_sequence):\n",
    "        if n > batch_limit:\n",
    "            break\n",
    "        prediction = model.predict(img_b)\n",
    "        for img, mask, pred in zip(img_b, mask_b, prediction):\n",
    "            y_true = mask[:,:,1]\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.subplot(141)\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Image\")\n",
    "        \n",
    "            plt.subplot(142)\n",
    "            plt.imshow(y_true)\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            plt.subplot(143)\n",
    "            plt.imshow(pred[:,:,1])\n",
    "            plt.title(\"Predicted\")\n",
    "            \n",
    "            plt.subplot(144)\n",
    "            rounded = np.array((pred[:,:,1] > threshold), dtype=np.float32)\n",
    "            intersection = np.logical_and(y_true, rounded).sum()\n",
    "            union = np.logical_or(y_true, rounded).sum()\n",
    "            iou = round(intersection / union, 2)\n",
    "            plt.imshow(rounded)\n",
    "            plt.title(f\"IoU: {iou}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "val_seq = make_sequence(monuseg_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(model, test_sequence, threshold=0.5, batch_limit=1):\n",
    "    for n, ((img_b, _), mask_b) in enumerate(test_sequence):\n",
    "        if n > batch_limit:\n",
    "            break\n",
    "        prediction = model.predict(img_b)\n",
    "        for img, mask, pred in zip(img_b, mask_b, prediction):\n",
    "            y_true = mask[:,:,1]\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.subplot(141)\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Image\")\n",
    "        \n",
    "            plt.subplot(142)\n",
    "            plt.imshow(y_true)\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            plt.subplot(143)\n",
    "            plt.imshow(pred[:,:,1])\n",
    "            plt.title(\"Predicted\")\n",
    "            \n",
    "            plt.subplot(144)\n",
    "            rounded = np.array((pred[:,:,1] > threshold), dtype=np.float32)\n",
    "            intersection = np.logical_and(y_true, rounded).sum()\n",
    "            union = np.logical_or(y_true, rounded).sum()\n",
    "            iou = round(intersection / union, 2)\n",
    "            plt.imshow(rounded)\n",
    "            plt.title(f\"IoU: {iou}\")\n",
    "\n",
    "display_result(model_inference, val_seq, 0.5)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
